{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42991dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models import get_pretrained_pretransform\n",
    "from export import remove_parametrizations\n",
    "\n",
    "import librosa, time\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "import cached_conv as cc\n",
    "\n",
    "cc.use_cached_conv(True)\n",
    "\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb03a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the autoencoder from stable-audio-open-1.0\n",
    "\n",
    "autoencoder, model_config = get_pretrained_pretransform(\"stabilityai/stable-audio-open-1.0\", \n",
    "                                                         model_half=True, \n",
    "                                                         skip_bottleneck=True, \n",
    "                                                         device=device)\n",
    "\n",
    "print(f\"sample_rate: {model_config.get('sample_rate', 'unknown')}\")\n",
    "print(f\"latent_dim: {model_config['model']['pretransform']['config'].get('latent_dim', 'unknown')}\")\n",
    "print(f\"downsampling_ratio: {model_config['model']['pretransform']['config'].get('downsampling_ratio', 'unknown')}\")\n",
    "print(f\"io_channels: {model_config['model']['pretransform']['config'].get('io_channels', 'unknown')}\")\n",
    "\n",
    "autoencoder = autoencoder.to(device)\n",
    "autoencoder.eval()\n",
    "\n",
    "remove_parametrizations(autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50129db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an example audio file and split into chunks\n",
    "\n",
    "buffer_size = 4096\n",
    "\n",
    "audio_path = librosa.example('fishin', hq=True)\n",
    "wv, sr = librosa.load(audio_path, sr=44100, mono=False)\n",
    "wv = torch.tensor(wv, device=device)[:,buffer_size*50:buffer_size*150].unsqueeze(0)  # make stereo, limit length for test\n",
    "wv_chunks = [wv[:, :, i*buffer_size:(i+1)*buffer_size] for i in range(100)]\n",
    "\n",
    "print(f'waveform shape: {wv.shape}')\n",
    "print(f'number of chunks: {len(wv_chunks)}')\n",
    "print(f'chunk shape: {wv_chunks[0].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a720383",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Running encoder, test device: {device}')\n",
    "## Run audio chunks to the encoder\n",
    "\n",
    "latent_chunks = []\n",
    "with torch.no_grad():\n",
    "    torch.cuda.synchronize() if device == \"cuda\" else torch.mps.synchronize()\n",
    "    start_time = time.perf_counter()\n",
    "    for i, w in enumerate(wv_chunks):\n",
    "        latent = autoencoder.encode(w)\n",
    "        latent_chunks.append(latent)\n",
    "    torch.cuda.synchronize() if device == \"cuda\" else torch.mps.synchronize()\n",
    "    end_time = time.perf_counter()\n",
    "    print(f'Encoder execution time: {end_time - start_time:.2f} seconds')\n",
    "        \n",
    "\n",
    "print(f'Running decoder, test device: {device}')\n",
    "## Run audio chunks to the decoder\n",
    "wv_recons = []\n",
    "with torch.no_grad():\n",
    "    torch.cuda.synchronize() if device == \"cuda\" else torch.mps.synchronize()\n",
    "    start_time = time.perf_counter()\n",
    "    for i, latent in enumerate(latent_chunks):\n",
    "        wv_recon = autoencoder.decode(latent)\n",
    "        wv_recons.append(wv_recon)\n",
    "    torch.cuda.synchronize() if device == \"cuda\" else torch.mps.synchronize()\n",
    "    end_time = time.perf_counter()\n",
    "    print(f'Decoder execution time: {end_time - start_time:.2f} seconds')\n",
    "wv_recon = torch.cat(wv_recons, dim=-1)\n",
    "print(f'reconstructed waveform shape: {wv_recon.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62700ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Original:\"\n",
    "display(Audio(wv.cpu().numpy()[0], rate=sr))\n",
    "\"Reconstructed:\"\n",
    "display(Audio(wv_recon.cpu().numpy()[0], rate=sr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stableaudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
